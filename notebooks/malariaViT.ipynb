{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c791958c",
   "metadata": {},
   "source": [
    "### Crop images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc273fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown class: difficult — skipping\n",
      "Unknown class: difficult — skipping\n",
      "Unknown class: difficult — skipping\n",
      "Unknown class: difficult — skipping\n",
      "Unknown class: difficult — skipping\n",
      "Unknown class: difficult — skipping\n",
      "Unknown class: difficult — skipping\n",
      "Unknown class: difficult — skipping\n",
      "Unknown class: difficult — skipping\n",
      "Unknown class: difficult — skipping\n",
      "Unknown class: difficult — skipping\n",
      "Unknown class: difficult — skipping\n",
      "Unknown class: difficult — skipping\n",
      "Unknown class: difficult — skipping\n",
      "Unknown class: difficult — skipping\n",
      "Unknown class: difficult — skipping\n",
      "Unknown class: difficult — skipping\n",
      "Unknown class: difficult — skipping\n",
      "Unknown class: difficult — skipping\n",
      "Unknown class: difficult — skipping\n",
      "Unknown class: difficult — skipping\n",
      " Done with cropping and saving images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "# Paths\n",
    "images_path = \"../A-Dataset-and-Benchmark-for-Malaria-Life-Cycle-Classification-in-Thin-Blood-Smear-Images/IML_Malaria\"\n",
    "annotation_path = \"../A-Dataset-and-Benchmark-for-Malaria-Life-Cycle-Classification-in-Thin-Blood-Smear-Images/annotations.json\"\n",
    "output_dir = \"cell_dataset/\"\n",
    "\n",
    "# Make map for each class\n",
    "classes = [\"ring\", \"trophozoite\", \"schizont\", \"gametocyte\", \"red blood cell\"]\n",
    "for cls in classes:\n",
    "    os.makedirs(os.path.join(output_dir, cls), exist_ok=True)\n",
    "\n",
    "# Load annotations\n",
    "with open(annotation_path) as f:\n",
    "    ground_truth = json.load(f)\n",
    "\n",
    "# Iterate through each image and its annotations\n",
    "for entry in ground_truth:\n",
    "    image_name = entry[\"image_name\"]\n",
    "    image_path = os.path.join(images_path, image_name)\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Bilde ikke funnet: {image_path}\")\n",
    "        continue\n",
    "\n",
    "    for i, obj in enumerate(entry[\"objects\"]):\n",
    "        label = obj[\"type\"]  \n",
    "        if label not in classes:\n",
    "            print(f\"Unknown class: {label} — skipping\")\n",
    "            continue\n",
    "\n",
    "        # Bounding box\n",
    "        x = int(obj[\"bbox\"][\"x\"])\n",
    "        y = int(obj[\"bbox\"][\"y\"])\n",
    "        w = int(obj[\"bbox\"][\"w\"])\n",
    "        h = int(obj[\"bbox\"][\"h\"])\n",
    "\n",
    "        # Crop and save\n",
    "        cropped = image.crop((x, y, x + w, y + h))\n",
    "        save_path = os.path.join(output_dir, label, f\"{image_name[:-4]}_{i}.png\")\n",
    "        if not os.path.exists(save_path):\n",
    "            cropped.save(save_path)\n",
    "        else:\n",
    "            print(f\"File {save_path} already exists, skipping save.\")\n",
    "print(\" Done with cropping and saving images.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d193bdd6",
   "metadata": {},
   "source": [
    "### Split data into train and valitadion set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29341ee0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cell_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(val_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# List all class folders\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m classes \u001b[38;5;241m=\u001b[39m [d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(input_dir) \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_dir, d))]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m classes:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSplitting class: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cell_dataset'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import shutil \n",
    "\n",
    "# Paths\n",
    "input_dir = \"cell_dataset\"        # Your full dataset with all images in class folders\n",
    "output_dir = \"data_split\"         # Where train/val folders will be created\n",
    "train_ratio = 0.8                 # 80% train, 20% validation split\n",
    "\n",
    "# For reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Create train and val directories\n",
    "train_dir = os.path.join(output_dir, \"train\")\n",
    "val_dir = os.path.join(output_dir, \"val\")\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "# List all class folders\n",
    "classes = [d for d in os.listdir(input_dir) if os.path.isdir(os.path.join(input_dir, d))]\n",
    "\n",
    "for cls in classes:\n",
    "    print(f\"Splitting class: {cls}\")\n",
    "    cls_input_path = os.path.join(input_dir, cls)\n",
    "    files = os.listdir(cls_input_path)\n",
    "    random.shuffle(files)  # Shuffle files before splitting\n",
    "\n",
    "    train_count = int(len(files) * train_ratio)\n",
    "    train_files = files[:train_count]\n",
    "    val_files = files[train_count:]\n",
    "\n",
    "    # Create class folders inside train and val directories\n",
    "    os.makedirs(os.path.join(train_dir, cls), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_dir, cls), exist_ok=True)\n",
    "\n",
    "    # Copy training files\n",
    "    for f in train_files:\n",
    "        shutil.copy2(os.path.join(cls_input_path, f), os.path.join(train_dir, cls, f))\n",
    "\n",
    "    # Copy validation files\n",
    "    for f in val_files:\n",
    "        shutil.copy2(os.path.join(cls_input_path, f), os.path.join(val_dir, cls, f))\n",
    "\n",
    "print(\"Dataset split into train and validation sets!\")\n",
    "\n",
    "# After splitting, delete the original dataset folder to save space\n",
    "shutil.rmtree(\"cell_dataset\")\n",
    "print(\"'cell_dataset' folder has been deleted to save space.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45f850d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522d08cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
